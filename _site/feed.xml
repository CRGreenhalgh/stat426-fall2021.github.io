<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-10-25T12:05:06-06:00</updated><id>/feed.xml</id><title type="html">Stat 426 - Fall 2021</title><subtitle>Class Blog and Projects</subtitle><entry><title type="html">Making Data Science Stick</title><link href="/blog/Learning-Data-Science" rel="alternate" type="text/html" title="Making Data Science Stick" /><published>2021-10-23T00:00:00-06:00</published><updated>2021-10-23T00:00:00-06:00</updated><id>/blog/Learning-Data-Science</id><content type="html" xml:base="/blog/Learning-Data-Science">&lt;p&gt;Learning data science is not always simple. Data science is composed by knowledge from different disciplines including math, statistics, and computer science. Because learning data science requires acquiring a great amount of knowledge, it would be useful to also learn a little bit about how we learn. If we learn how to more effectively acquire new knowledge, store it, and retrieve it when necessary, we will be able to keep up with advancing technologies and become more efficient data scientists.&lt;/p&gt;

&lt;h2 id=&quot;principles-of-successful-learning&quot;&gt;Principles of Successful Learning&lt;/h2&gt;

&lt;p&gt;In this article, I will talk about seven principles mentioned in the book &lt;strong&gt;Make it Stick: The Science of Successful Learning&lt;/strong&gt;. I will then provide examples of how to apply each of these principles when learning data science.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://images-na.ssl-images-amazon.com/images/I/51lagMtiKaL.jpg&quot; alt=&quot;Make it Stick Cover&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The seven principles are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Retrieval practice&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spaced, varied practice&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Desirable difficulties&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Elaboration, generation, and reflection&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The illusion of knowing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Learning preferences vs. learning styles&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Growth mindset&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;principle-1-retrieval-practice&quot;&gt;Principle 1: Retrieval practice&lt;/h2&gt;

&lt;p&gt;There is a big difference between repeating a concept to yourself after you just read it and trying to actively retrieve it. For example, when studying for a test, we might read again and again that the Central Limit Theorem is the name of the theorem stating that the sampling distribution of a statistic is approximately normal whenever the sample is large and random. After reading it several times, we might think that we know what the Central Limit Theory is. However, we would be confusing familiarity with actual knowledge. It is not until we can actively retrieve its definition from memory (without looking at the text again) that we can say that we know what the Central Limit Theorem actually is.&lt;/p&gt;

&lt;p&gt;The good news is that retrieval not only allows us to know whether we have learned something or not. It also helps us learn. Like Aristotle said, ‘the things we have to learn before we can do them, we learn by doing them.’ Trying to actively retrieve knowledge solidifies that knowledge in our memories. Therefore, we can use retrieval practice to test our knowledge, but we can also use it to help us retain it.&lt;/p&gt;

&lt;p&gt;A possible application of this principle would be to think of possible test questions while we are reading the material by the professor or while listening to lectures. This principle is particularly useful in very conceptual classes, such as statistics. Then, you can try to answer those questions.&lt;/p&gt;

&lt;p&gt;Retrieval practice will allow us to store knowledge in our long-term memory, and this is when the next principle can come in handy.&lt;/p&gt;

&lt;h2 id=&quot;principle-2-spaced-varied-practice&quot;&gt;Principle 2: Spaced, varied practice&lt;/h2&gt;

&lt;p&gt;In order to make sure that we can use information stored in our long-term memory when we need it the most, we have to practice retrieving that information at different times and in different contexts. If we try to retrieve a memory right before we are about to forget it, we are strengthening that connection in our mind. Therefore, we are consolidating that memory and engaging our long-term memory.&lt;/p&gt;

&lt;p&gt;In addition, we should switch topics during our study sessions to further consolidate our knowledge. But there’s another advantage to that, which is that we can relate what we are learning in different classes. For example, we might be taking linear algebra and linear regression. If we are studying the properties of matrices and how to perform different operations with them, and then switch to the topics to the importance of independence in linear regression, we can see how these topics are connected. We would be creating even more connections in our brains, consolidating memories and learning how to apply our knowledge in the appropriate context.&lt;/p&gt;

&lt;h2 id=&quot;principle-3-desirable-difficulties&quot;&gt;Principle 3: Desirable difficulties&lt;/h2&gt;

&lt;p&gt;While being a college student can be hard enough, we can benefit from adding - or simply embracing - certain difficulties into our learning. There are many easy ways to ‘study,’ but this doesn’t mean that they are the most efficient practices. For example, like we talked about before, it is easier to read a passage several times and think that we have learned that content just because we are familiar with the text than quizzing ourselves on those concepts.&lt;/p&gt;

&lt;p&gt;It might be counter-intuitive to think of difficulties as desirable, but when we struggle with a problem and try to come up with solutions (even if we fail), our learning improves. Results will appear to come slower, but they will be better and will last longer.&lt;/p&gt;

&lt;p&gt;Classes such as Probability and Inference or programming classes are great opportunities to try this principle. For example, we can first look at the practice problems at the end of the chapter and try to solve them, then we can read the chapter and try to solve them again. This will give you an opportunity to struggle and try to produce your own solutions. You will then be more prepared to learn the correct way to solve them.&lt;/p&gt;

&lt;h2 id=&quot;principle-4-elaboration-generation-and-reflection&quot;&gt;Principle 4: Elaboration, generation, and reflection&lt;/h2&gt;

&lt;p&gt;This principle might be the easiest to apply. If you form a study group, you can use that opportunity to explain difficult concepts to each other. Coming up with examples or analogies is what this principle is about. If you teach a difficult concept to someone else, you will be forced to elaborate and reflect on the subject. This will consolidate your own understanding and will clearly show you if you have any deficiencies in your knowledge.&lt;/p&gt;

&lt;p&gt;To summarize this principle, I like to say that to be a good student you should try to be a good teacher.&lt;/p&gt;

&lt;h2 id=&quot;principle-5-the-illusion-of-knowing&quot;&gt;Principle 5: The illusion of knowing&lt;/h2&gt;

&lt;p&gt;As statisticians, we know that our assumptions are not always met, so we need a way to test them. One assumption students commonly hold is that they understand a topic when they truly don’t. This is why we need different objective ways to test our knowledge and make sure that this assumption is met. It’s just like the common phrase: if you can’t measure it, you can’t improve it. One way to do this, which is related to previous principles, would be to test ourselves. Quizzes give us an objective measure of our knowledge since we can see how many questions we get right or wrong. In addition, we can make a note of the topic that each question is testing so that we can study that topic further.&lt;/p&gt;

&lt;p&gt;Use practice tests provided by your professors, practice questions in your textbook, and programming challenges found on the internet.&lt;/p&gt;

&lt;h2 id=&quot;principle-6-learning-preferences-vs-learning-styles&quot;&gt;Principle 6: Learning preferences vs. learning styles&lt;/h2&gt;

&lt;p&gt;This principle is very interconnected with the previous principle. Most of the time, we enjoy doing the things we are naturally good at. It’s human nature. However, what is easy is not always the same as what is best. Like we talked about before, you don’t want to focus on only doing things you are naturally good at because 1) you will think that you know more than you do and 2) it is not necessarily what promotes learning.&lt;/p&gt;

&lt;p&gt;For example, if you are good at making diagrams but bad at taking quizzes, you have to make sure that you practice both. Or, if you are good at coding but don’t really understand the underlying assumptions of the analysis you are performing, you shouldn’t focus on what you prefer or are good at, but you should instead focus on what you are lacking or need to improve so that you promote your learning and not your ego.&lt;/p&gt;

&lt;h2 id=&quot;principle-7-growth-mindset&quot;&gt;Principle 7: Growth mindset&lt;/h2&gt;

&lt;p&gt;Finally, you might feel that you are not smart enough to be a data scientist or that you are having too many difficulties. If this is the case, it is important to remember that intelligence is not set but is malleable. In addition, you will now have the right tools and learning strategies to exponentially improve your learning process. Learning is more a marathon than a sprint, and having a growth mindset will help you stay motivated to reach your goals.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://edsurge.imgix.net/uploads/post/image/12467/mind_as_muscle-1565189295.jpg?auto=compress%2Cformat&amp;amp;w=1024&amp;amp;h=512&amp;amp;fit=crop&quot; alt=&quot;Growth Mindset Conclusion&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The most important part of becoming a data scientist is having the right approach. It is not only about intelligence or hard work, it is also about putting in the right kind of work and being consistent. In addition, it is important to remember that there are many resources available to students to make their learning path easier to navigate. Learning is not something we do once and then forget about it, it is something we are doing all the time. Therefore, we might as well get good at it.&lt;/p&gt;</content><author><name>Gerardo Meza Mera</name><email>meza.mera.gerardo@gmail.com</email></author><category term="Learning" /><category term="Retrieval practice" /><category term="Study strategies" /><summary type="html">Learning data science is not always simple. Data science is composed by knowledge from different disciplines including math, statistics, and computer science. Because learning data science requires acquiring a great amount of knowledge, it would be useful to also learn a little bit about how we learn. If we learn how to more effectively acquire new knowledge, store it, and retrieve it when necessary, we will be able to keep up with advancing technologies and become more efficient data scientists.</summary></entry><entry><title type="html">Automating a Python Script on a Mac</title><link href="/blog/python-auto" rel="alternate" type="text/html" title="Automating a Python Script on a Mac" /><published>2021-10-22T00:00:00-06:00</published><updated>2021-10-22T00:00:00-06:00</updated><id>/blog/python-auto</id><content type="html" xml:base="/blog/python-auto">&lt;p&gt;Automating a python script to run on a certain interval can be extremely convenient and useful. When working with dynaimc data, automating a script can be especially convenient in order to keep up with a constant influx of new data. It can save lots of time as well, so that you don’t have to manually run your script each time you want it to be ran. No matter what your python script does, you can automate it - and that’s pretty awesome. There are multiple ways to automate a python script to run on a specified schedule, and some may be better than others. I do not claim to be an expert about any of these ways, but I can show you one way to automate a python script. This post is for Mac users, unfortunately I will not be covering the different nuances for Windows users. I will essentially be covering the three steps necessary to automating/scheduling a python script. These steps are not limited to python files, but that will be the example I am using. The following steps can be summed up as:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Write a python script.&lt;/li&gt;
  &lt;li&gt;Make the script executable.&lt;/li&gt;
  &lt;li&gt;Automate/schedule the script to run.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;lets-get-started&quot;&gt;Let’s get started!&lt;/h1&gt;

&lt;h2 id=&quot;1&quot;&gt;1&lt;/h2&gt;
&lt;p&gt;First up, you need a python script that you want to run. The example I am using is a python script that is pulling COVID data from an API, converting the data into a pandas dataframe, and saving the data to a csv. Obviously there is much more you can do than just save a csv. Your script can send an email, populate a database, update a dashboard, etc. This is just a simple example, the focus of this post is meant to be on the automation of the script and not on the script itself. My code is fairly simple, but don’t worry too much about all the specifics of the code, I will comment next to the relevant lines.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-22/pyscript.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see from the comments in my code, there are a few important things to notice. First off is setting the path where you want the file to be downloaded. If you forget this step, it might take you a second to find where the output of your file was downloaded. In order to stay organized, I have set the file path so that I know where to find the output from my script. Additionally, getting the timestamp is really helpful. Because I add the timestamp to the name of my file, I will be able to discern when a specific file was output from my python script. Lastly, saving my data to a csv is essentially my end deliverable. I could have saved it in a different format,or perhaps emailed the data somewhere or uploaded it elsewhere, there are several possibilites as I mentioned earlier. In this case, I wanted to donwload a file each time the script ran so I could be extra sure that the automation of the file was working correctly.&lt;/p&gt;

&lt;h2 id=&quot;2&quot;&gt;2&lt;/h2&gt;
&lt;p&gt;Now that I have my python script, it’s time to automate it. To do this, I first need to make my script executable. Follow the steps below to do this.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Open the terminal and run pip install pyinstaller. This will install PyInstaller.&lt;/li&gt;
  &lt;li&gt;Inside the terminal, navigate to the directory where your script is located.&lt;/li&gt;
  &lt;li&gt;Once you‘re in the path where your script is located, run the following ‘pyinstaller –onefile example.py’ in the terminal to make the script executable.&lt;/li&gt;
  &lt;li&gt;You should see a message that includes “completed successfully.” Then in the directory where your script is located, you should see a folder named “dist”. Click inside that folder and you will find the executable. You’ll need to know the path to this executable, so keep this in mind for later.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;3&quot;&gt;3&lt;/h2&gt;
&lt;p&gt;Okay now your python script is executable - hooray! Next up, we are going to automate this script to run at a specified interval by using crontab.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Open the terminal and run crontab -e.&lt;/li&gt;
  &lt;li&gt;Press ‘i’ to activate the INSERT mode.&lt;/li&gt;
  &lt;li&gt;Use https://crontab.guru/ to write how often you want the script to run.
(example: ‘* * * * *’ would make the script run every minute)&lt;/li&gt;
  &lt;li&gt;After you specify when the script will run, press SPACE, put the path to the executable you just created, press SPACE again, and put the path to your script.
(example: * * * * * /path/to/my/executable /path/to/my/script)&lt;/li&gt;
  &lt;li&gt;Press esc. and then type :wq to save and exit (w - write, q - quit) and then press enter.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To make sure that the crontab was created, type ‘crontab -l’ in the terminal and you should see it. To edit the crontab, type ‘crontab -e’. To remove the crontab, type ‘crontab -r’.&lt;/p&gt;

&lt;h2 id=&quot;congrats-you-just-automated-your-python-script&quot;&gt;Congrats, you just automated your python script!&lt;/h2&gt;
&lt;p&gt;As I mentioned, this is not the only way to automate a script, but it is one simple and effective way that I have found. I hope this post was helpful in some way and that you learned something new!&lt;/p&gt;

&lt;h3 id=&quot;a-few-things-to-know&quot;&gt;A few things to know:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;If you have don’t have the right permissions, you need to give full disk access. Click System Preferences, Security and Privacy, Privacy, and Full Disk Access and then grant access.&lt;/li&gt;
  &lt;li&gt;If for whatever reason your crontab is not working, you can type ‘mail’ in the terminal and then press enter to see potential error messages.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rex Moss</name><email>rexxmoss@gmail.com</email></author><category term="crontab" /><category term="pandas" /><category term="terminal" /><category term="mac" /><summary type="html">Automating a python script to run on a certain interval can be extremely convenient and useful. When working with dynaimc data, automating a script can be especially convenient in order to keep up with a constant influx of new data. It can save lots of time as well, so that you don’t have to manually run your script each time you want it to be ran. No matter what your python script does, you can automate it - and that’s pretty awesome. There are multiple ways to automate a python script to run on a specified schedule, and some may be better than others. I do not claim to be an expert about any of these ways, but I can show you one way to automate a python script. This post is for Mac users, unfortunately I will not be covering the different nuances for Windows users. I will essentially be covering the three steps necessary to automating/scheduling a python script. These steps are not limited to python files, but that will be the example I am using. The following steps can be summed up as:</summary></entry><entry><title type="html">Rolling Back Commits in Git</title><link href="/blog/rollback-commits" rel="alternate" type="text/html" title="Rolling Back Commits in Git" /><published>2021-10-21T00:00:00-06:00</published><updated>2021-10-21T00:00:00-06:00</updated><id>/blog/rollback-commits</id><content type="html" xml:base="/blog/rollback-commits">&lt;p&gt;As all data scientists know, coding can do weird things during routine processes. Whether it’s an unexpected data type returning errors on a dataframe method or a regular expression returning an extra space, small changes to code can drastically change the outcome of any project. One of the processes that produces such odd outcomes at an unexpectedly high rate is moving code that functions on a local machine to a production-level application. While these errors can be largely prevented by updating branches with the main repository at least daily to ensure data quality, sometimes small logic errors creep into production that can break downstream models or lead to data loss, both of which can be detrimental to business models. Happily, Git offers many options to quickly remove the offending lines of code until the error can be fixed, thus returning the code to its previously functioning state.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\dont-touch-my-code.jpg&quot; alt=&quot;Dont touch the code&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;rolling-back-commits-using-git&quot;&gt;Rolling Back Commits using Git&lt;/h1&gt;
&lt;p&gt;Note: For all of the following commands, the offending commit needs to be identified in order to remove it. Some help for debugging can be found in this article: &lt;a href=&quot;https://www.vinta.com.br/blog/2015/3-awesome-git-commands/&quot;&gt;3 Awesome Git Commands&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;revert&quot;&gt;Revert&lt;/h2&gt;
&lt;p&gt;First on the list is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt;. The revert command keeps with the idea behind Git that changes should be documented so that collaborators can understand why the code has been changed. In essence, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; reverses the effects of unwanted commits (i.e. adds deleted lines and deletes added lines) through a series of new commits. These new commits ensure that the changes are documented so that other programmers (including future you) know why not to do what was just done. Using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; in its base form is very simple. Just type the command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; followed by the names of the offending commits. For example, suppose that we make the following git repository along with the commits shown.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\initial-stuff.jpg&quot; alt=&quot;initial-stuff.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now new_file.txt contains ‘Stat 426’, with a newline after ‘Stat’. Now we make an error in our code as shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\not-wanted.jpg&quot; alt=&quot;error&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, stating that Stat 426 is dumb is an undesirable addition to our code and is something we want to get rid of. We will use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; to change it back. We first use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reflog&lt;/code&gt; to find the commit names, which is fairly simple since our repository is so small. We know that ‘commit 3’ is the one we want to change, so we use the id associated with it to reverse the changes with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt;, as seen below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\Revert-saves-day.jpg&quot; alt=&quot;revert-save-day&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As shown above in the second usage of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reflog&lt;/code&gt;, there is an extra commit listed that states that we reverted the changes from ‘commit 3’ because the statement made about the class wasn’t true. Now new_file.txt is restored to its previous state, without the false information inside of it.&lt;/p&gt;

&lt;p&gt;For more information about &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt;, see the &lt;a href=&quot;https://git-scm.com/docs/git-revert&quot;&gt;git revert documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;reset&quot;&gt;Reset&lt;/h2&gt;

&lt;p&gt;While &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; is sufficient when the changes made can be traced back to one bad commit, its ability to work with many undesirable changes over multiple commits is limited by the coder’s desire to input every single commit id until reaching the commit with the code they want. In contrast, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset&lt;/code&gt; excels at such tasks. Instead of reverting changes from one commit, it resets the repository to a specific commit, getting rid of the changes made after the desired commit. For example, consider a repository with a file called ‘new_file.txt’, as shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\good-reset.jpg&quot; alt=&quot;good-reset&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The file ‘new_file.txt’ now holds desirable code and is committed. However, further material is added and committed as shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\reset-bad.jpg&quot; alt=&quot;bad-reset&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While everything may look correct above, upon further inspection there is a mistake. We accidentally overwrote the file and didn’t realize it! Now the code is incomplete and incorrect, as shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\reset-realize.jpg&quot; alt=&quot;realize-reset&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This kind of situation is where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset&lt;/code&gt; is useful. Because the additional code following the overwritten file is incorrect and spans multiple commits, we can’t just get rid of the offending code with one &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; command. However, we can reset our commits to the functioning code with one command, as follows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\reset-fix.jpg&quot; alt=&quot;fix-reset&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As shown above, the correct code from a previous commit replaced the faulty code, which was the desired effect. However, using this format, there isn’t an option to name the commit that records the reset. Notwithstanding, a commit will be made that records the change.&lt;/p&gt;

&lt;p&gt;For more information about &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset&lt;/code&gt;, &lt;a href=&quot;https://git-scm.com/docs/git-reset&quot;&gt;click here to check the documentation for git reset&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;restore&quot;&gt;Restore&lt;/h2&gt;

&lt;p&gt;While &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset&lt;/code&gt; work well to restore previous commits, it is often useful to restore previous commits only for certain files instead of rewriting each file the commit touched. This is easily achieved by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git restore&lt;/code&gt;. While the same function can be fulfilled using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git checkout&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git restore&lt;/code&gt; tends to be less complicated since it is intended for restoring specific files instead of entire branches, which is why we use it here. However, since the command is still experimental and subject to change, checking the documentation often is highly recommended. &lt;a href=&quot;https://git-scm.com/docs/git-restore&quot;&gt;Click here to check the documentation for git restore&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In order to show how it works, consider an example with two files that contain good content. They have been commited as shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\restore-begin.jpg&quot; alt=&quot;initial restore&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, after the first commit, some unwanted content is added. It is subsequently committed, and is now part of our code.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\restore-bad.jpg&quot; alt=&quot;bad stuff&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After the undesirable content is added, some desirable content is added and committed as well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\restore-good.jpg&quot; alt=&quot;good stuff&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, if we reverted or restored to the first commit, we would lose the desired code in new_file2.txt and need to redo our work! While that would be trivial here, in larger scale cases, such a scenario would most likely mean at least hours of work would need to be redone. Therefore, we will restore only the file with undesirable content to the original commit and leave the other file alone. Using the reflog command to find the commit id, we can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git restore&lt;/code&gt; to get the original content of the file back.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets\images\blogimages\figs-10-21\restore-final.jpg&quot; alt=&quot;final restore&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As shown above, the file with undesirable content was changed back to way it was in the specified commit and our other file was left alone. However, the changes we made are still uncommitted, so be warned!&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Because coding is a large part of data science, every data scientist will make mistakes that will get committed. To think otherwise is naive at best. Therefore, it is important to know how to remove those errors. When those errors get committed to a repository, using  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git revert&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git restore&lt;/code&gt; can be extremely useful in changing faulty new code back to production-level old code.&lt;/p&gt;</content><author><name>Jace Ritchie</name><email>ritchie.jace@gmail.com</email></author><category term="revert" /><category term="git" /><category term="rollback" /><category term="commit" /><summary type="html">As all data scientists know, coding can do weird things during routine processes. Whether it’s an unexpected data type returning errors on a dataframe method or a regular expression returning an extra space, small changes to code can drastically change the outcome of any project. One of the processes that produces such odd outcomes at an unexpectedly high rate is moving code that functions on a local machine to a production-level application. While these errors can be largely prevented by updating branches with the main repository at least daily to ensure data quality, sometimes small logic errors creep into production that can break downstream models or lead to data loss, both of which can be detrimental to business models. Happily, Git offers many options to quickly remove the offending lines of code until the error can be fixed, thus returning the code to its previously functioning state.</summary></entry><entry><title type="html">Build a Markov Chain Text Generation Twitter Bot</title><link href="/blog/markov-twitter" rel="alternate" type="text/html" title="Build a Markov Chain Text Generation Twitter Bot" /><published>2021-10-20T00:00:00-06:00</published><updated>2021-10-20T00:00:00-06:00</updated><id>/blog/markov-twitter</id><content type="html" xml:base="/blog/markov-twitter">&lt;h2 id=&quot;so-you-want-to-build-a-twitter-bot&quot;&gt;So you want to build a Twitter bot.&lt;/h2&gt;

&lt;p&gt;For whatever reason, you thought it might be fun to take the social out of social media and make a robot do it. You’re in good company; Twitter is full of bots ranging from artsy, to helpful, to downright problematic. I would encourage you to think deeply about the purpose of your bot and only move forward if you’re sure it’ll have a net benefit on society, or at least just breaks even.&lt;/p&gt;

&lt;p&gt;With that out of the way, let’s get to it. Check out the bot I made with this tutorial to see what we’ll be building:&lt;/p&gt;

&lt;h3 id=&quot;stat-426-twitter-bot&quot;&gt;&lt;a href=&quot;https://twitter.com/stat426bot&quot;&gt;STAT 426 Twitter Bot&lt;/a&gt;&lt;/h3&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Lucky for us, this is a task with clearly defined steps. There are lots of different kinds of Twitter bots you can make, and it can be a bit more complicated to build one that does anything more advanced than just tweeting, like replying to comments or otherwise interacting with users. Feel free to explore on your own and be creative, but this tutorial will only go over how to make a bot that tweets a generated phrase.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Please note that these are Mac-specific instructions, but with some googling, each step should be very similar to what you’ll need to do if you’re on a Windows or Linux machine.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To reach our goal, we’ll have to go through the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Find a corpus from which to generate tweets.&lt;/li&gt;
  &lt;li&gt;Generate tweets with Markovify.&lt;/li&gt;
  &lt;li&gt;Set up a Twitter Developer Account.&lt;/li&gt;
  &lt;li&gt;Write a script to tweet via the Twitter API.&lt;/li&gt;
  &lt;li&gt;Put the script on a timer to tweet at specific intervals.&lt;/li&gt;
  &lt;li&gt;Enjoy fame.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;build-a-corpus&quot;&gt;Build a Corpus&lt;/h2&gt;

&lt;p&gt;A corpus is a source text. It can be a book, a website–anything with words. I’ve made Twitter bots using quotes from the host of TV’s Survivor Jeff Probst, a journalist from The Atlantic, and BYU Speeches, so there are plenty of options to choose from. For this example, we’ll be making a Data Science Blog bot and use the other articles on this website as the source corpus. First, I’ll need to stitch together all the blogs into one file. Because I have them all in the repo cloned onto my machine, I can use this very simple linux command from the Terminal on Mac:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;md&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;md&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;The cat function concatenates and outputs the content of provided files. *.md matches all Markdown files in the directory and the “&amp;gt;” operator writes that output into the file I name.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-20/corpus.png&quot; alt=&quot;Screenshot of corpus file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This step can also be accomplished by copy-pasting your desired source text from articles, books, etc. into one file. With your corpus file built, we can use Python to generate sentences from this. We’ll use the Markovify package for this.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;generating-text-with-markov-chains&quot;&gt;Generating Text with Markov Chains&lt;/h2&gt;

&lt;p&gt;Text generation can be done using a variety of methods ranging in difficulty and quality of output. We’ll stick with an easier method that utilizes &lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_chain&quot;&gt;Markov Chains&lt;/a&gt;, but it should be noted that the quality of your generated text depends heavily on the quality of your corpus. Inane, incomprehensible sentences aren’t a sign of something going wrong, that’s kinda just the way these work.&lt;/p&gt;

&lt;p&gt;There is a lot that you can read about Markov Chains, which are used in modeling applications ranging from animal populations to currency exchange rates. In short, a Markov Chain is a model made up of discrete ‘states’ which map to outcomes that occur at defined probabilities. It’s very similar to a finite state machine, with the difference of probability rather than input defined transitions. For example, a Markov Chain that models the weather might have a raining state, with a certain probability that it continues to rain, a probability that it starts snowing, a probability that it stops raining, etc. In the case of text generation, a Markov Chain creates a sentence word by word using the source corpus as a model. That model is comprised of each and every word in the corpus mapped to any number of outcomes as the word that could potentially follow the first, with the probability that the outcome occurs defined as the proportion of the times that word appears after the first word in the corpus. Whew. Maybe this diagram of the model based on a one-sentence corpus will help:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“the quick brown fox jumps over the lazy dog.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-20/pangram.png&quot; alt=&quot;Markov Chain visualization of the famous pangram.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A sentence is generated by following the flowchart adding each word you pass to your sentence in the order you pass it. This sentence obviously doesn’t have many words from which to build a model, so generated sentences won’t be especially interesting or unique. With a few more sentences, however, the model begins to take a more concrete form. Here’s another Markov Chain that represents this quote about Breath of the Wild:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“This is the new world of Zelda. It is quite a vast world is it not? You can even reach those mountains in the distance, if you walk far enough. We could not create such a wide world like this in the past.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-20/botw.png&quot; alt=&quot;Breath of the Wild Markov Model.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you want to do anything more complicated with Text Generation for your Twitter Bot, you might check out &lt;a href=&quot;https://openai.com&quot;&gt;OpenAI&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To make these models from text in Python, we’ll use a package called &lt;a href=&quot;https://pypi.org/project/markovify&quot;&gt;Markovify&lt;/a&gt;. Go ahead and install the package. If you’re using pip, you can run the command&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;markovify&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first step when using this package is to build the model from your file. Read your corpus into python and instantiate a Text object from markovify:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;markovify&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/path/to/my/corpus.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;text_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;markovify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now generate a sentence of up to 280 characters (the Twitter character limit) using make_short_sentence(280).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;generated_sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_short_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;280&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One such sentence generated from the Zelda quote above might look like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘We could not create such a wide world like this in the distance, if you walk far enough.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Something that greatly affects the quality of your model is the ‘state_size’ parameter. This defines the number of words that are included in each state or word group from which the outcome word is predicted. Increasing this parameter will often improve the intelligibility of your sentences. The default state size is 2 words, and the syntax to change it is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;markovify.Text(corpus, state_size=3)&lt;/code&gt;. Just remember that the larger you set the state parameter, the closer your generated sentences will look to your corpus sentences. Set this lower if you don’t want repeated sentences. Markovify automatically rejects sentences that overlap too much with the corpus so as to not just regurgitate provided content, but after 10 attempt to find a unique sentence it will give up and use whatever it can.&lt;/p&gt;

&lt;p&gt;I’ve built a Markov Chain model using the articles of all other authors on this blog. A few of my favorite sample sentences it generated include:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘Through a process of learning a new branch to develop that part of the model trains.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘In addition to all the time. It may say that it is a programming language that will allow you to easily and thus provide more accurate rating system, and then the class, I need to do calculations and make better traffic control decisions.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘After you complete the prerequisites correctly then when you run your program you it will automatically upload your index.html file at a given speed.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For comparison, these are the kind of sentences I can generate when I set state_size to 1:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘This library called Matplotlib.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘First we want, when I am still in python.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Not only to learn to customer demands, as I’ve simply start by the turning angle?”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pretty good, right? In fact, this entire article was generated by a bot trained on thousands of Text Generation blog posts! Just kidding, but that would be cool.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applying-for-a-twitter-developer-account&quot;&gt;Applying for a Twitter Developer Account&lt;/h2&gt;

&lt;p&gt;Now that we can generate tweets from our corpus, we need to set up a script to automate tweeting them out. To do this, we’ll need access to the Twitter API which allows for these type of operations. It is generally pretty easy to set up an account, but it may take a day or two to get approved.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-20/twitter.png&quot; alt=&quot;Twitter sign up prompt&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Navigate to twitter.com to set up a new account for your bot. The easiest way to do this is by selecting “Sign up with phone or email” and using the email option. If you don’t or can’t use your personal email to make this account (Twitter doesn’t allow multiple accounts on the same email), you can put a ‘+’ sign after your handle and before the ‘@’ sign to create a subaddress that Twitter will accept i.e. /myemail+twitterbot@gmail.com. You’ll have to add a bio, profile picture, etc. or skip these options for now.&lt;/p&gt;

&lt;p&gt;Now that you have a Twitter account for your bot, we need to upgrade to a developer account at developer.twitter.com. This is free, but requires filling out a few forms to get approval from Twitter. It’s a fairly simple process that they use to screen out potentially dangerous bots (think Russian election bots).&lt;/p&gt;

&lt;p&gt;At developer.twitter.com, click through Apply &amp;gt; Apply for a developer account &amp;gt; Hobbyist &amp;gt; Making a bot &amp;gt; Get started. It will then require you to add a phone number before proceeding, this number can be associated with multiple accounts. You’ll then need to answer questions asked in the form, and may need to resolve follow up emails.&lt;/p&gt;

&lt;p&gt;Once you have developer access, navigate to your developer dashboard at developer.twitter.com. Click ‘create project’, and fill out the form in order to generate authentication keys for your bot. Eventually you’ll get to a ‘keys and tokens’ page. Save the API Key and API Key Secret for writing the script in the next step. Navigate to App Settings, where you’ll need to change App Permissions to ‘Read and Write’. Click on ‘Keys and Tokens’, and generate an Access Token and Secret. Save these with the other key and secret.&lt;/p&gt;

&lt;p&gt;That was a lot, but these steps should keep your bot secure. Never share these keys publicly. If you ever need to regenerate the user keys, you’ll have to update them in your script.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;using-the-twitter-api&quot;&gt;Using the Twitter API&lt;/h2&gt;

&lt;p&gt;Now that we have access to the Twitter API, we’re going to use a Python wrapper called Twython to access it easily. You’ll need to generate access tokens and other keys in order to authenticate your API access, this is how Twitter verifies that you have a developer account. Do NOT share these or post these keys anywhere.&lt;/p&gt;

&lt;p&gt;In order to set up the wrapper, replace the appropriate field with your keys and tokens in the following code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;twython&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Twython&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;APP_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'your key'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;APP_SECRET&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'your secret'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ACCESS_TOKEN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'your token'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ACCESS_SECRET&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'your secret'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;twitter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Twython&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;APP_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;APP_SECRET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ACCESS_TOKEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ACCESS_SECRET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now to tweet something, you’ll just have to call the update_status() method on your Twython object passing in the text to tweet as a status parameter.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;twitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tweet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And that’s it! Combine this code with your text generating code to get a short script like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;twython&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Twython&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;markovify&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;APP_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;APP_SECRET&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ACCESS_TOKEN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ACCESS_SECRET&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;twitter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Twython&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;APP_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;APP_SECRET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ACCESS_TOKEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ACCESS_SECRET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;corpus.md&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;text_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;markovify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tweet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_short_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;280&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;twitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tweet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And that’s it! Run the script now and check twitter to see if your tweet sent successfully.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;scheduling-your-tweets&quot;&gt;Scheduling your tweets&lt;/h2&gt;

&lt;p&gt;The last thing we to do is to put our script on a timer. Crontab is an excellent tool for scheduling scripts to run at a certain time, the only caveat is that your computer will need to be awake at the time you specify, so choose a time when that is most likely to be true. I recommend reading more about it at &lt;a href=&quot;https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx/&quot;&gt;this website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We’ll access Crontab through the command line by running this command in your computer’s terminal:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;env EDITOR=nano crontab -e
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This opens up Crontab to be edited, using nano as the editor. In the editor, type this code, replacing the path with your script.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0 12 * * *  /path/to/script/markov_twitter.py&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The numbers and asterisks before the path represent time intervals in cron syntax. This particular code means that the script will run at noon every day. If you’d like to edit the timing or change the frequency, check out &lt;a href=&quot;https://crontab.guru&quot;&gt;crontab guru&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It may take some trial and error to get working correctly to ensure you have the correct filepath, and you’ll likely need to change the permissions on your script to allow crontab to run it by executing code like this:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;chmod u+rwx markov_twitter.py&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Note that you can also set up a raspberry pi to run cron jobs, if you’d rather not have to remember to wake your computer up at the right time each day.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;At this point, we’ve been through a lot together. We’ve built a corpus of text, used markov chains to generate sentences from it, connected to the Twitter API, tweeted using a python script, and put it all on a timer. Feel free to comment with any bot ideas or links to bots you make!&lt;/p&gt;</content><author><name>Scot Nielson</name><email>scotnielson616@gmail.com</email></author><category term="Twitter" /><category term="Python" /><category term="Markov Chains" /><category term="Text Generation" /><category term="Bot" /><summary type="html">So you want to build a Twitter bot.</summary></entry><entry><title type="html">How to Excel at Microsoft Excel with Python Library openpyxl</title><link href="/blog/excel-in-python" rel="alternate" type="text/html" title="How to Excel at Microsoft Excel with Python Library openpyxl" /><published>2021-10-19T00:00:00-06:00</published><updated>2021-10-19T00:00:00-06:00</updated><id>/blog/excel-in-python</id><content type="html" xml:base="/blog/excel-in-python">&lt;p&gt;For many in the world, Microsoft Excel is the most advanced tool in their toolbox of data analytics. And to be fair, it is an extremely powerful software. You can manipulate data in all sorts of ways, write functions and equations, create insightful graphics, and format data in a way that pleases the eye. However, many times as a data scientist, simply using Excel is not going to cut it. In today’s post, I want to go over some helpful functions that are introduced by using the library openpyxl, as well as some helpful ones found in pandas. We will cover reading in Excel files, writing to Excel files, as well as working in real time with an Excel file.
To start, we are going to go over what is possible with simply using the pandas library. Reading in an Excel sheet is quite similar to reading in a .csv file. A unique difference is the ability to specify a sheet name for workbooks that have more than just one sheet. Using the below syntax, the Excel sheet is read in as a pandas DataFrame that can easily be used for feature engineering and further analysis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image1.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Writing a DataFrame into an Excel workbook can also be done. I find this quite helpful for when your intended audience will want to see the cleaned up version of your data, or if you plan to use Excel to add color and formatting. Below is an example of how this is done. Once again, the arguments for the to_excel() function are unique in the fact they cater to things only found in Excel. For example, you are able to specify the sheet name, as well as on which row or column you would like your data to begin placing information.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image3.png&quot; alt=&quot;open&quot; /&gt;
&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image4.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These functions are found simply in the pandas library and are quite valuable. However, using the openpyxl library will enable you to go a little bit further. There is a plethora of ways to use it, but today I want to go over the three main functions needed to get started. The first is loading an existing Excel workbook into python as a Workbook object.&lt;/p&gt;

&lt;p&gt;After importing Workbook and load_workbook from the library, and having an existing Workbook in a callable directory, we are good to get started. Using load_workbook(‘file_path’) allows us to call an Excel Workbook.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image5.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As seen above, workbook object types have a several unique aspects. First, they can have multiple sheets, which needs to be called in order to access their data. In addition, you can specify certain cells by referencing their location in Excel fashion, or also by specifying the row and column. Just be sure to add .value to the end in order to actually access the value within the cell.&lt;/p&gt;

&lt;p&gt;Cell values can also be changed while in Python. Just make sure you specify .value！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image65.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Saving your python code by itself does not save the changes you have made in the Excel workbook. To do this, you can simply call the .save(‘file_name.xlsx’) off of the workbook object. Keep in mind, the file needs to be closed to both load and save it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image7.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also initialize a new workbook in python by calling Workbook(), as seen below. Know that it automatically starts with one sheet, but you can create more if you want. By default, it adds new sheets to the end, but this can be changed in the .create_sheet() syntax. Check out my example below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image8.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can loop both through the Worksheets, and through the cells. Personally I think this is a super powerful tool, because it is something that is quite difficult to pull off in Excel, but rather straightforward in Python.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image9.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Again, your workbook only exists in Python until you use the .save() function to create a .xlsx file on your computer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-19/image91.png&quot; alt=&quot;open&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In a world that loves Microsoft Office, having the ability to perform Python level analysis on Excel files is a must for any data scientist. I hope that my quick tutorial helps get you started. Keep in mind, the openpyxl library has a lot more to offer, as I really only scratched the surface. Good luck!&lt;/p&gt;</content><author><name>Josh Degn</name><email>jhdegn@gmail.com</email></author><category term="Excel" /><category term="openpyxl" /><category term="Microsoft Office" /><category term="spreadsheets" /><summary type="html">For many in the world, Microsoft Excel is the most advanced tool in their toolbox of data analytics. And to be fair, it is an extremely powerful software. You can manipulate data in all sorts of ways, write functions and equations, create insightful graphics, and format data in a way that pleases the eye. However, many times as a data scientist, simply using Excel is not going to cut it. In today’s post, I want to go over some helpful functions that are introduced by using the library openpyxl, as well as some helpful ones found in pandas. We will cover reading in Excel files, writing to Excel files, as well as working in real time with an Excel file. To start, we are going to go over what is possible with simply using the pandas library. Reading in an Excel sheet is quite similar to reading in a .csv file. A unique difference is the ability to specify a sheet name for workbooks that have more than just one sheet. Using the below syntax, the Excel sheet is read in as a pandas DataFrame that can easily be used for feature engineering and further analysis.</summary></entry><entry><title type="html">Reinforcement Racing</title><link href="/blog/deep-racer" rel="alternate" type="text/html" title="Reinforcement Racing" /><published>2021-10-16T00:00:00-06:00</published><updated>2021-10-16T00:00:00-06:00</updated><id>/blog/deep-racer</id><content type="html" xml:base="/blog/deep-racer">&lt;h3 id=&quot;what-is-reinforcement-learning&quot;&gt;What is Reinforcement learning?&lt;/h3&gt;

&lt;p&gt;In the late 1800s, a psychologist named Ivan Pavlov conducted now famous experiments, proving that over time, dogs could learn to associate the sound of a bell with food. This lead to the concept of classical conditioning, and modern learning theories.&lt;/p&gt;

&lt;p&gt;We’ve known for a long time that incentives change behavior. You can teach a dog tricks by offering treats, and you can improve a child’s attitude by offering cookies. Reinforcement learning is applying the same tactics to an artificial intelligence.&lt;/p&gt;

&lt;h3 id=&quot;reward-functions&quot;&gt;Reward Functions&lt;/h3&gt;

&lt;p&gt;But how can we incentivize a computer to behave in the ways we want, when it neither needs or understands a primal desire for food? Or anything for that matter?&lt;/p&gt;

&lt;p&gt;Well, computers have always been a lot better than humans at math, so what if we programmed them to optimize a number? Many reinforcement learning models start with rules for awarding points. This is often called a reward function. Through a process of trial and error, the program will start to discover which behaviors maximize it’s points, and it will try successful strategies more often.&lt;/p&gt;

&lt;h3 id=&quot;amazon-deepracer&quot;&gt;Amazon DeepRacer&lt;/h3&gt;

&lt;p&gt;Amazon DeepRacer is a way to learn about and practice reinforcement learning by training a small racecar to drive around a track.&lt;/p&gt;

&lt;p&gt;Here’s footage from BYU’s 2019 DeepRacer event to give you an idea what it looks like.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/6yUcWqdQH5w&quot;&gt;&lt;img src=&quot;https://img.youtube.com/vi/6yUcWqdQH5w/0.jpg&quot; alt=&quot;BYU DeepRacer&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/6yUcWqdQH5w&quot;&gt;2019 DeepRacer Event&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In machine learning terms, the racetrack is the &lt;em&gt;environment&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The car is an &lt;em&gt;agent&lt;/em&gt;. An agent is the entity that can take actions, with the consequences of those actions altering the environment, and hopefully ‘teaching’ the agent to make better decisions. For an Amazon DeepRacer vehicle, the actions it can take are to change the angle of its wheels, and change it’s speed.&lt;/p&gt;

&lt;p&gt;The agent regularly receives data about it’s &lt;em&gt;state&lt;/em&gt;. Where is the agent in the environment and what kind of conditions is the car in? What is the turning angle? Are all wheels on the track? How fast is the car going? In addition to all of this, the deepracer vehicle has a camera in the front to take a picture of whats in front of it. The model crunches all this data to decide how the car will drive.&lt;/p&gt;

&lt;p&gt;But you don’t make the model. All you write is the reward function, and the model is written and changed as the model trains. During these training simulations, the car drives around a virtual track, and you can watch in real time as the model improves. The racecar will truly learn to drive itself, starting with random decisions and refining them as it gets points in each iteration.&lt;/p&gt;

&lt;p&gt;You’ll definitely want at least an hour of training, but eventually, your model may become overfit for the specific track you trained on. The ideal training parameters and time of the training are all part of the secret sauce that makes deepracing fun.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-16/DRsimulation.png&quot; alt=&quot;DR Simulation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;lets-race&quot;&gt;Let’s Race!&lt;/h3&gt;

&lt;p&gt;I challenge you to beat my model (though I doubt it will be very hard). Luckilly, reward functions are written in Python, and aren’t complicated to get started with!&lt;/p&gt;

&lt;p&gt;I’ve created a link where our class can pit our models against each other:
&lt;a href=&quot;https://console.aws.amazon.com/deepracer/home#raceToken/g_Jv-1ZVQrynlcB1GgLPpg&quot;&gt;Enter the Race!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You’ll need to sign up for an AWS account, which would normally require your credit or debit card, but as a student, you can sign up for an AWS educate account and have one year of free-tier computing for free:
&lt;a href=&quot;https://www.awseducate.com/registration#APP_TYPE&quot;&gt;AWS Educate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If, like me, you’ve already timed out of your educate account, don’t worry, Amazon offers ten hours of model training/evaluation for free in a generic account (but you do need to supply card details). As always, when working in the cloud, pay attention to costs, know where the free-tier cutoffs are, and keep your login credentials private!&lt;/p&gt;

&lt;p&gt;Once you have an account, the free training I’ve linked below provides everything you need to get started. It’s honestly a little addicting watching your little bot scoot around the virtual track while doing training simulations.
&lt;a href=&quot;https://www.aws.training/Details/eLearning?id=32143&quot;&gt;Quick Start Guide&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Happy racing!&lt;/p&gt;</content><author><name>Israel Bentley</name><email>israel.bentley@icloud.com</email></author><category term="reinforcement" /><category term="learning" /><category term="deep" /><category term="racing" /><summary type="html">What is Reinforcement learning?</summary></entry><entry><title type="html">Bringing Statistics Into A Fictional World</title><link href="/blog/OpenDota" rel="alternate" type="text/html" title="Bringing Statistics Into A Fictional World" /><published>2021-10-15T00:00:00-06:00</published><updated>2021-10-15T00:00:00-06:00</updated><id>/blog/OpenDota</id><content type="html" xml:base="/blog/OpenDota">&lt;h1 id=&quot;statistics-in-dota&quot;&gt;Statistics in DotA&lt;/h1&gt;

&lt;p&gt;The field of statistics is broad. It is nearly impossible to find a single facet of life that can’t have statistical analysis applied to it.
In my years of studying statistical analysis, I have also spent a fair amount of time playing a video game known as Defense of the Ancients 2, or DotA 2.&lt;/p&gt;

&lt;p&gt;This game features a ton, so I wont go into detail, but the basic premise is a 5 VS 5 battle arena. 5 real people play as one of over 100 unique heroes vs a team of 5 other real people with their respective heroes.&lt;/p&gt;

&lt;p&gt;The goal? Destroy the enemies base and their Ancient, a structure that gives them their power.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-15/dotaexample.png&quot; alt=&quot;dotaart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With so many variables and variations possible, I thought it would be a fun project to do a bit of analysis on my personal data. I have played thousands of games over the years. That is a lot of Data that I can perform analysis on.&lt;/p&gt;

&lt;p&gt;This is made possible with &lt;a href=&quot;opendota.com&quot;&gt;OpenDota&lt;/a&gt;. Using the API function, I am able to get all my personal data from the beginning of when I started to play.&lt;/p&gt;

&lt;h1 id=&quot;how-i-did-it&quot;&gt;How I did it&lt;/h1&gt;

&lt;p&gt;I start by importing Pandas and requests. The requests package simplifies working with https requests. The resulting files can then be read into pandas DataFrames with the &lt;strong&gt;pandas.read_json()&lt;/strong&gt; function.&lt;/p&gt;

&lt;p&gt;The data we requested is in Json form, which is similar to a dictionary. Pandas included function parses through it and makes a tidy DataFrame from it.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;requests&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;https://api.opendota.com/api/players/96974530/matches&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;df&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-15/df1.png&quot; alt=&quot;df1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So now we have the raw data from every match I have ever played in. I don’t want to dive too deep into what is possible, so why don’t I just compare something like how long a match is when compared to the hero I played. I can do this many ways, but I will be making a boxplot of the &lt;em&gt;duration&lt;/em&gt; column with specific &lt;em&gt;hero_id&lt;/em&gt; column values.&lt;/p&gt;

&lt;p&gt;I will first make a subset of the data frame with just where hero_id = 18 and 90. These ID numbers represent the Heroes Sven and Keeper of the Light (KotL). Then I will plot the duration of both and compare how long the games lasted when I chose one or the other.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;subset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;hero_id&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;isin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;plot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;column&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;hero_id&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Game Duration Comparison&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Sven                                                 KotL&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Duration (minutes)&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-15/boxplot.png&quot; alt=&quot;boxplot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that there is not much difference between the two, but there is a slight increase in duration when I choose KotL compared to when I choose Sven. But this is just one very simple analysis you can do. OpenDota allows for deep analysis of many variables, and as a statistician who loves the game I want to be able to better understand how I play and improve.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;There are a ton of other things you can perform data analysis on, and it helps when you do it with something you love! I would suggest you find something that means a lot to you that you can perform some form of statistical analysis on to better understand not only what you love, but how statistics is used all around us to make connections!&lt;/p&gt;

&lt;p&gt;If you want to learn more about the game, go to the &lt;a href=&quot;dota2.com/home&quot;&gt;DotA 2 website&lt;/a&gt;&lt;/p&gt;</content><author><name>John Black</name><email>john.black.4306@gmail.com</email></author><category term="Statistical analysis" /><category term="Dota 2" /><category term="API" /><category term="pandas" /><summary type="html">Statistics in DotA The field of statistics is broad. It is nearly impossible to find a single facet of life that can’t have statistical analysis applied to it. In my years of studying statistical analysis, I have also spent a fair amount of time playing a video game known as Defense of the Ancients 2, or DotA 2. This game features a ton, so I wont go into detail, but the basic premise is a 5 VS 5 battle arena. 5 real people play as one of over 100 unique heroes vs a team of 5 other real people with their respective heroes. The goal? Destroy the enemies base and their Ancient, a structure that gives them their power. With so many variables and variations possible, I thought it would be a fun project to do a bit of analysis on my personal data. I have played thousands of games over the years. That is a lot of Data that I can perform analysis on. This is made possible with OpenDota. Using the API function, I am able to get all my personal data from the beginning of when I started to play. How I did it I start by importing Pandas and requests. The requests package simplifies working with https requests. The resulting files can then be read into pandas DataFrames with the pandas.read_json() function. The data we requested is in Json form, which is similar to a dictionary. Pandas included function parses through it and makes a tidy DataFrame from it. import pandas as pd import requests r = requests.get('https://api.opendota.com/api/players/96974530/matches') df = pd.read_json(r.text) df So now we have the raw data from every match I have ever played in. I don’t want to dive too deep into what is possible, so why don’t I just compare something like how long a match is when compared to the hero I played. I can do this many ways, but I will be making a boxplot of the duration column with specific hero_id column values. I will first make a subset of the data frame with just where hero_id = 18 and 90. These ID numbers represent the Heroes Sven and Keeper of the Light (KotL). Then I will plot the duration of both and compare how long the games lasted when I chose one or the other. subset = df.loc[df['hero_id'].isin([18, 90])] plot = subset.boxplot(column=['duration'], by=['hero_id']) plot.set_title('Game Duration Comparison') plot.set_xlabel('Sven KotL') plot.set_ylabel('Duration (minutes)') plt.show() We can see that there is not much difference between the two, but there is a slight increase in duration when I choose KotL compared to when I choose Sven. But this is just one very simple analysis you can do. OpenDota allows for deep analysis of many variables, and as a statistician who loves the game I want to be able to better understand how I play and improve. Conclusion There are a ton of other things you can perform data analysis on, and it helps when you do it with something you love! I would suggest you find something that means a lot to you that you can perform some form of statistical analysis on to better understand not only what you love, but how statistics is used all around us to make connections! If you want to learn more about the game, go to the DotA 2 website</summary></entry><entry><title type="html">What is Pyenv and Why You Should Use It</title><link href="/blog/pyenv-tutorial" rel="alternate" type="text/html" title="What is Pyenv and Why You Should Use It" /><published>2021-10-14T00:00:00-06:00</published><updated>2021-10-14T00:00:00-06:00</updated><id>/blog/pyenv-tutorial</id><content type="html" xml:base="/blog/pyenv-tutorial">&lt;p&gt;When you install Python on your computer, you should constantly update your Python version as new ones come out. Unfortunately, some libraries can become obsolete because they are not supported by the current version making code that once worked a major headache to update. Additionally, if you have ever tried to collaborate with other people in a project, they could have different libraries and python versions making it so you have to spend lots of time updating and debugging something that should be a fix. Fortunately, there is a tool that can help mitigate this, so you always know what python version you’re using and what libraries are being used in a project.&lt;/p&gt;

&lt;h1 id=&quot;what-is-pyenv&quot;&gt;What is Pyenv?&lt;/h1&gt;

&lt;p&gt;Pyenv is a tool to manage different python versions on your computer for each project. Essentially you can have Python 2.7.15, Python 3.6.8, ect … what ever you need, all on your computer and create virtual environments in these versions to make your projects run smoothly. In short, pyenv lets you change the global Python version, install multiple Python versions, set project-specific Python versions, and create and manage virtual python environments. Instructions to install pyenv on your computer can be found &lt;a href=&quot;https://github.com/pyenv/pyenv#installation&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;pyenv-order&quot;&gt;Pyenv Order&lt;/h1&gt;

&lt;p&gt;Pyenv organizes your system, global, local, and shell versions and can be thought about in a pyramid.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.realpython.com/media/pyenv-pyramid.d2f35a19ded9.png&quot; alt=&quot;pyenv-pyramid&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;System - this is what is installed on your computer when you download python&lt;/li&gt;
  &lt;li&gt;Global - global python version can be changed with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt; pyenv global 3.6.8 &amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Local - this is often project specific python versions&lt;/li&gt;
  &lt;li&gt;Shell - for shell specific python versions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using the command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;pyenv versions&amp;gt;&lt;/code&gt; will Show what versions of python you have installed and will denote your current global version with and asterisk.&lt;/p&gt;

&lt;p&gt;This example shows what this could look like in your computer.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/blogimages/figs-10-14/pyen_versions&quot;&gt;pyenv example&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can see that there are several versions of python installed but I am currently working off the system version. Additionally, I have created some virtual environments for specific projects. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt; 3.9.6/envs/pyenv_practice &amp;gt;&lt;/code&gt; being one of them. For a full tutorial on how to set different versions and virtual environments, use the sources at the the end of this blog post.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Typically, things like this can be hard to understand until it is put into practice. Below I have done the following to demonstrate how a local python version can be made for a specific project:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Set the local version to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;pyenv local 3.9.1&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Show the versions and that my local has been set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;3.9.1&amp;gt;&lt;/code&gt; as denoted by the astrisk&lt;/li&gt;
  &lt;li&gt;Create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;practice.py script&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Show all file in the directory with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt; ls -a &amp;gt;&lt;/code&gt; and show that in  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;.python-version&amp;gt;&lt;/code&gt; the version is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;3.9.1&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Go up a level to show that global python is still set to the system and the practice folder is different.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/blogimages/figs-10-14/Example&quot;&gt;quick Example&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;Hopefully you can see how useful pyenv can be when working on different project! Setting your local version can help you manage what packages you are using and know what all the dependencies are for what you are doing. Some next steps you can do on your own are learning how to use pyenv while collaborating and creating/installing your requirements.txt or other python managers.&lt;/p&gt;

&lt;p&gt;Sources :
  &lt;a href=&quot;https://realpython.com/intro-to-pyenv/&quot;&gt;Real Python&lt;/a&gt;
  &lt;a href=&quot;https://amaral.northwestern.edu/resources/guides/pyenv-tutorial#:~:text=Meet%20pyenv%3A%20a%20Simple%20Python,environments%20(%22virualenv's%22).&quot;&gt;North Western&lt;/a&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/75935407/138190483-eb2596d2-0689-4691-a1e6-fd01d8b165f1.png&quot; alt=&quot;image&quot; /&gt;
—
title: “What is Pyenv and Why You Should Use It”
layout: post
author: 18katesmit
post-image: “https://files.realpython.com/media/Getting-Started-With-pyenv_Watermarked.7b1dd55b32a1.jpg”
description: A Brief Intro to Multiple Python Versions with Pyenv
tags:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;python&lt;/li&gt;
  &lt;li&gt;python libraries&lt;/li&gt;
  &lt;li&gt;virtual environment&lt;/li&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;versions&quot;&gt;versions&lt;/h2&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you install Python on your computer, you should constantly update your Python version as new ones come out. Unfortunately, some libraries can become obsolete because they are not supported by the current version making code that once worked a major headache to update. Additionally, if you have ever tried to collaborate with other people in a project, they could have different libraries and python versions making it so you have to spend lots of time updating and debugging something that should be a fix. Fortunately, there is a tool that can help mitigate this, so you always know what python version you’re using and what libraries are being used in a project.&lt;/p&gt;

&lt;h1 id=&quot;what-is-pyenv-1&quot;&gt;What is Pyenv?&lt;/h1&gt;

&lt;p&gt;Pyenv is a tool to manage different python versions on your computer for each project. Essentially you can have Python 2.7.15, Python 3.6.8, ect … what ever you need, all on your computer and create virtual environments in these versions to make your projects run smoothly. In short, pyenv lets you change the global Python version, install multiple Python versions, set project-specific Python versions, and create and manage virtual python environments. Instructions to install pyenv on your computer can be found &lt;a href=&quot;https://github.com/pyenv/pyenv#installation&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;pyenv-order-1&quot;&gt;Pyenv Order&lt;/h1&gt;

&lt;p&gt;Pyenv organizes your system, global, local, and shell versions and can be thought about in a pyramid.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.realpython.com/media/pyenv-pyramid.d2f35a19ded9.png&quot; alt=&quot;pyenv-pyramid&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;System - this is what is installed on your computer when you download python&lt;/li&gt;
  &lt;li&gt;Global - global python version can be changed with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt; pyenv global 3.6.8 &amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Local - this is often project specific python versions&lt;/li&gt;
  &lt;li&gt;Shell - for shell specific python versions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using the command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;pyenv versions&amp;gt;&lt;/code&gt; will Show what versions of python you have installed and will denote your current global version with and asterisk.&lt;/p&gt;

&lt;p&gt;This example shows what this could look like in your computer.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/blogimages/figs-10-14/pyen_versions&quot;&gt;pyenv example&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can see that there are several versions of python installed but I am currently working off the system version. Additionally, I have created some virtual environments for specific projects. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt; 3.9.6/envs/pyenv_practice &amp;gt;&lt;/code&gt; being one of them. For a full tutorial on how to set different versions and virtual environments, use the sources at the the end of this blog post.&lt;/p&gt;

&lt;h2 id=&quot;example-1&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Typically, things like this can be hard to understand until it is put into practice. Below I have done the following to demonstrate how a local python version can be made for a specific project:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Set the local version to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;pyenv local 3.9.1&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Show the versions and that my local has been set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;3.9.1&amp;gt;&lt;/code&gt; as denoted by the astrisk&lt;/li&gt;
  &lt;li&gt;Create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;practice.py script&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Show all file in the directory with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt; ls -a &amp;gt;&lt;/code&gt; and show that in  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;.python-version&amp;gt;&lt;/code&gt; the version is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;3.9.1&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Go up a level to show that global python is still set to the system and the practice folder is different.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/blogimages/figs-10-14/Example&quot;&gt;quick Example&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusions-1&quot;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;Hopefully you can see how useful pyenv can be when working on different project! Setting your local version can help you manage what packages you are using and know what all the dependencies are for what you are doing. Some next steps you can do on your own are learning how to use pyenv while collaborating and creating/installing your requirements.txt or other python managers.&lt;/p&gt;

&lt;p&gt;Sources :
  &lt;a href=&quot;https://realpython.com/intro-to-pyenv/&quot;&gt;Real Python&lt;/a&gt;
  &lt;a href=&quot;https://amaral.northwestern.edu/resources/guides/pyenv-tutorial#:~:text=Meet%20pyenv%3A%20a%20Simple%20Python,environments%20(%22virualenv's%22).&quot;&gt;North Western&lt;/a&gt;&lt;/p&gt;</content><author><name>Kate Smith</name><email>18kate.smith@gmail.com</email></author><category term="python" /><category term="python libraries" /><category term="virtual environment" /><category term="versions" /><summary type="html">When you install Python on your computer, you should constantly update your Python version as new ones come out. Unfortunately, some libraries can become obsolete because they are not supported by the current version making code that once worked a major headache to update. Additionally, if you have ever tried to collaborate with other people in a project, they could have different libraries and python versions making it so you have to spend lots of time updating and debugging something that should be a fix. Fortunately, there is a tool that can help mitigate this, so you always know what python version you’re using and what libraries are being used in a project.</summary></entry><entry><title type="html">Expanding Your Tools as a Data Scientist: Learning Python After R</title><link href="/blog/R-to-Python" rel="alternate" type="text/html" title="Expanding Your Tools as a Data Scientist: Learning Python After R" /><published>2021-10-13T00:00:00-06:00</published><updated>2021-10-13T00:00:00-06:00</updated><id>/blog/R-to-Python</id><content type="html" xml:base="/blog/R-to-Python">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In my data science education, I started with learning R to manipulate datasets and create visualizations. There are, however, many different coding languages that can be used to accomplish these tasks. Different companies and people have different preferences as far as coding languages, so it is important to be familiar with many different types of languages. Learning different types of languages can be difficult as it involves learning syntax, packages, and setups.
One of the most popular coding languages for data science is Python. Python is an object-oriented, high level programing language. The purpose of this post is to suggest some different tips for learning Python after R to make for a smoother transition.&lt;/p&gt;
&lt;h2 id=&quot;data-types&quot;&gt;Data Types&lt;/h2&gt;
&lt;p&gt;The first thing that one needs to understand when learning Python after R is the differences in the data types. Data types are important because they tell the computer how to interpret the value. It ensures that the data will be collected in the preferred format. When your data is reported as a certain datatype it will prevent you from using certain functions unless you change the data type. Due to that it is important to know the different data types, what you can do with them, and how to change them. Both R and Python use predefined datatypes. Python supports the following data types:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Numbers- Python stores numeric values. They can be stored in 4 different data types.
•	Integers- Whole numbers. Python’s integer is the same as R’s integer.
•	Long- long integers that are represented in octa and hexadecimal. In R you have to use the bit64 packages to read hexadecimal values.
•	Complex- Complex numbers like i. They are the same in both R and Python.
•	Float- Decimal values. Unlike in Python, R uses the numeric data type.&lt;/li&gt;
  &lt;li&gt;Boolean- Stores true and false values. The difference between R and Python in this data type is that in R the Boolean values are store in all capital characters, TRUE and FALSE, and in Python the first character in capital and the rest are lower case, True and False. In R Boolean values can be stored in factor or character data types.&lt;/li&gt;
  &lt;li&gt;Lists- They can be used to store strings, Boolean, integers, and etc. Lists are the same in R and Python.&lt;/li&gt;
  &lt;li&gt;Strings- As mentioned above strings can be store in list. Strings themselves store character data. This would be the same as R’s character data type.&lt;/li&gt;
  &lt;li&gt;Tuples- These do not exist in R but they would be like a R vector whose values would be immutable.&lt;/li&gt;
  &lt;li&gt;Dictionary- Has a two-dimensional structure that has a key and value pair.
    &lt;h2 id=&quot;packages&quot;&gt;Packages&lt;/h2&gt;
    &lt;p&gt;Another helpful thing to know when transitioning from Python after learning R would be to know what packages help to preform data manipulation and machine learning. This allows you to use python like you would R. Some of the helpful packages are:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Scikit Learn- This package allows you to preform machine learning algorithms. This package contains all the functions that you would need to build a model.&lt;/li&gt;
  &lt;li&gt;Numpy- This allows you to preform numerical computing in python. With numpy you can preform things like linear algebra, statistics etc. In the documentation you can see the different functions that you can see and their options.&lt;/li&gt;
  &lt;li&gt;Pandas- In R you can use libraries like dplyr to preform data manipulation. In Python you would use Pandas. Pandas allows you to make data frames and then manipulate them. You can tidy your data set and determine what data you want to use to do calculations and make visualizations.&lt;/li&gt;
  &lt;li&gt;Matplotlib- I remember when I was first learning R the first thing we were taught was how to make plots using the library ggplot2. In Python you can use Matplotlib. There are also many other packages you can use to preform data visualization so you can experiment with different ones. Some different ones are plotly express and seaborn.
    &lt;h2 id=&quot;why-would-you-learn-python&quot;&gt;Why Would You Learn Python?&lt;/h2&gt;
    &lt;p&gt;With so many similarities one might wonder why it would be important to learn Python if they already know R. Some strengths of Python are:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Scrapping Data- Python packages, like Beautiful Soup, make it much simpler to scrape data from the internet.&lt;/li&gt;
  &lt;li&gt;Text processing- With different packages available in Python it is much easier to process text data. Python is an object-oriented langue that has a clean syntax that helps when working with text data. One such package is regex which allows you to work with regular expressions.
With these helpful tools available in Python, data collection, manipulation and visualization is aided. This is not to say that knowing R is not important, but that knowledge of both tools is helpful when pursuing a career in Data Science.
    &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
    &lt;p&gt;In conclusion, there are many different programming languages that you can use in data science. Two such languages are Python and R. It can be difficult to learn different languages. If you’re like me and trying to learn Python as your second language after R there are some important things to know before starting. It is important to know how data types differ in the two languages and what packages you can use to fo the same things that you would do in R. In the sometimes frustrating process of learning a new language it is also important to remember the strengths of the programming language that will allow you to do things simpler or that you couldn’t do before.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Rosie Stewart</name><email>erstewart14@gmail.com</email></author><category term="R" /><category term="Python" /><category term="Packages" /><summary type="html">Introduction In my data science education, I started with learning R to manipulate datasets and create visualizations. There are, however, many different coding languages that can be used to accomplish these tasks. Different companies and people have different preferences as far as coding languages, so it is important to be familiar with many different types of languages. Learning different types of languages can be difficult as it involves learning syntax, packages, and setups. One of the most popular coding languages for data science is Python. Python is an object-oriented, high level programing language. The purpose of this post is to suggest some different tips for learning Python after R to make for a smoother transition. Data Types The first thing that one needs to understand when learning Python after R is the differences in the data types. Data types are important because they tell the computer how to interpret the value. It ensures that the data will be collected in the preferred format. When your data is reported as a certain datatype it will prevent you from using certain functions unless you change the data type. Due to that it is important to know the different data types, what you can do with them, and how to change them. Both R and Python use predefined datatypes. Python supports the following data types: Numbers- Python stores numeric values. They can be stored in 4 different data types. • Integers- Whole numbers. Python’s integer is the same as R’s integer. • Long- long integers that are represented in octa and hexadecimal. In R you have to use the bit64 packages to read hexadecimal values. • Complex- Complex numbers like i. They are the same in both R and Python. • Float- Decimal values. Unlike in Python, R uses the numeric data type. Boolean- Stores true and false values. The difference between R and Python in this data type is that in R the Boolean values are store in all capital characters, TRUE and FALSE, and in Python the first character in capital and the rest are lower case, True and False. In R Boolean values can be stored in factor or character data types. Lists- They can be used to store strings, Boolean, integers, and etc. Lists are the same in R and Python. Strings- As mentioned above strings can be store in list. Strings themselves store character data. This would be the same as R’s character data type. Tuples- These do not exist in R but they would be like a R vector whose values would be immutable. Dictionary- Has a two-dimensional structure that has a key and value pair. Packages Another helpful thing to know when transitioning from Python after learning R would be to know what packages help to preform data manipulation and machine learning. This allows you to use python like you would R. Some of the helpful packages are: Scikit Learn- This package allows you to preform machine learning algorithms. This package contains all the functions that you would need to build a model. Numpy- This allows you to preform numerical computing in python. With numpy you can preform things like linear algebra, statistics etc. In the documentation you can see the different functions that you can see and their options. Pandas- In R you can use libraries like dplyr to preform data manipulation. In Python you would use Pandas. Pandas allows you to make data frames and then manipulate them. You can tidy your data set and determine what data you want to use to do calculations and make visualizations. Matplotlib- I remember when I was first learning R the first thing we were taught was how to make plots using the library ggplot2. In Python you can use Matplotlib. There are also many other packages you can use to preform data visualization so you can experiment with different ones. Some different ones are plotly express and seaborn. Why Would You Learn Python? With so many similarities one might wonder why it would be important to learn Python if they already know R. Some strengths of Python are: Scrapping Data- Python packages, like Beautiful Soup, make it much simpler to scrape data from the internet. Text processing- With different packages available in Python it is much easier to process text data. Python is an object-oriented langue that has a clean syntax that helps when working with text data. One such package is regex which allows you to work with regular expressions. With these helpful tools available in Python, data collection, manipulation and visualization is aided. This is not to say that knowing R is not important, but that knowledge of both tools is helpful when pursuing a career in Data Science. Conclusion In conclusion, there are many different programming languages that you can use in data science. Two such languages are Python and R. It can be difficult to learn different languages. If you’re like me and trying to learn Python as your second language after R there are some important things to know before starting. It is important to know how data types differ in the two languages and what packages you can use to fo the same things that you would do in R. In the sometimes frustrating process of learning a new language it is also important to remember the strengths of the programming language that will allow you to do things simpler or that you couldn’t do before.</summary></entry><entry><title type="html">Using SQL in Different Programming Languages</title><link href="/blog/sql-in-coding" rel="alternate" type="text/html" title="Using SQL in Different Programming Languages" /><published>2021-10-12T00:00:00-06:00</published><updated>2021-10-12T00:00:00-06:00</updated><id>/blog/sql-in-coding</id><content type="html" xml:base="/blog/sql-in-coding">&lt;p&gt;SQL, short for Structured Query Language, is a programming language used for database management. 
It’s language was standardized around the time the first personal computers were being released, and
since then it’s continued to be used for managing most large datasets. While many people are familiar with
using SQL to query data warehouses, there are ways to take advantage of its language in other programming
applications.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blogimages/figs-10-12/mysql.jpeg&quot; alt=&quot;MySQL&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;using-sql-through-a-database&quot;&gt;Using SQL through a database&lt;/h2&gt;

&lt;p&gt;When someone uses SQL, they’re usually using it to query a database. Most database management engines, such
as MySQL, PostgreSQL, SQLite, Oracle, and Microsoft Access each use SQL to perform their queries. APIs
for databases also often use SQL. Although some specifics may vary from program to program, the overall
language tends to be very standardized. For example, the following query will return the petal length
of every setosa in the “iris” dataset:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Petal_Length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Species&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setosa&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you’re pulling data directly from a data warehouse, you can typically use queries like this to format 
and filter the data so you only download what you need. However, sometimes you are obtaining the data
from another source, such as a csv file. Most of these files will need some sort of data cleaning, and 
while the language you’re using likely has methods for this cleaning built in, the queries provided by
SQL might seem like a desirable alternative. Thankfully, most programming languages have some way to
perform SQL queries on data that’s already been imported.&lt;/p&gt;

&lt;h2 id=&quot;sql-in-python-pandasql&quot;&gt;SQL in Python: pandasql&lt;/h2&gt;

&lt;p&gt;In Python, the &lt;a href=&quot;https://pypi.org/project/pandasql/&quot;&gt;pandasql&lt;/a&gt; package lets you query pandas dataframes
as if they were in your data warehouse, and will return another pandas dataframe. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sqldf&lt;/code&gt; method
in the package requires two arguments. The first argument is a string containing the query you want to
submit, while the second indicates whether the dataframe you want to query is in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;locals()&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;globals()&lt;/code&gt;.
Running the method will perform that query, returning a dataframe.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandasql&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqldf&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;setosaPetals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqldf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT Petal_Length FROM iris WHERE Species = setosa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;globals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you’re doing several queries in one program, it may be tedious to include &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;locals()&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;globals()&lt;/code&gt; in
every instance. In that case, you can define a function to include it for you:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandasql&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqldf&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pysqldf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqldf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;globals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;setosaPetals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pysqldf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT Petal_Length FROM iris WHERE Species = setosa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;sql-in-r-sqldf&quot;&gt;SQL in R: sqldf&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://www.rdocumentation.org/packages/sqldf/&quot;&gt;sqldf&lt;/a&gt; package in R is very similar to the pandasql 
package in Python. Because R doesn’t use methods and doesn’t typically distinguish between 
local and global variables, sqldf takes less code than pandasql. Otherwise, they are essentially the
same; simply input a string query, and it will be run on the specified data frame so long as it’s been
defined in your local environment.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-splus&quot;&gt;library(sqldf)
setosaPetals &amp;lt;- sqldf(&quot;SELECT Petal_Length FROM iris WHERE Species = setosa&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;sql-in-sas-proc-sql&quot;&gt;SQL in SAS: PROC SQL&lt;/h2&gt;

&lt;p&gt;Another programming language you may wish to use SQL in is SAS. SAS is set up quite differently than
most other programming languages, since it’s already very focused on manipulating tables. In fact, a
method of manipulating tables using SQL is built in to SAS!&lt;/p&gt;

&lt;p&gt;The 
&lt;a href=&quot;https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/sqlproc/n1lhnlzhrmrqggn1rz570u89oq2m.htm&quot;&gt;PROC SQL&lt;/a&gt;
step works similarly to other &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;proc&lt;/code&gt; steps, but with a few differences. Most notably, you need to end your 
step with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quit;&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run;&lt;/code&gt;. Otherwise, simply input your query as a single statement to send the
result to your output:&lt;/p&gt;

&lt;div class=&quot;language-sas highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PROC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SQL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Petal_Length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Species&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setosa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;QUIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you’d rather send the query results to another table, simply start the query with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create table&lt;/code&gt;
followed by the name of the new table:&lt;/p&gt;

&lt;div class=&quot;language-sas highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PROC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SQL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setosaPetals&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Petal_Length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Species&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setosa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;QUIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;SQL queries are a versatile tool for manipulating data from data warehouses, but that’s not their only
usage. Even if you already have data loaded into your environment, you can often perform queries on that
data. While other tools exist that can reshape the data into what you need, SQL is a simple and 
consistent tool that can be used in many different programs.&lt;/p&gt;</content><author><name>Andrew Pope</name><email>tunasaladx@gmail.com</email></author><category term="SQL" /><category term="Data cleaning" /><category term="Programming languages" /><summary type="html">SQL, short for Structured Query Language, is a programming language used for database management. It’s language was standardized around the time the first personal computers were being released, and since then it’s continued to be used for managing most large datasets. While many people are familiar with using SQL to query data warehouses, there are ways to take advantage of its language in other programming applications.</summary></entry></feed>